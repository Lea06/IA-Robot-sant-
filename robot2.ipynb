{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import speech_recognition as sr\n",
    "import os\n",
    "from langchain.chains import StuffDocumentsChain, LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "os.environ['OPEN_API_KEY']='sk-proj-MgwdEZ7nwXLtf5poVrUrT3BlbkFJo77w3iUBszaxUHlVio3n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trigger script**\n",
    "\n",
    "Note : Rajouter fonction d'arrêt (mouvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the recognizer\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Function to listen for the wake word\n",
    "def listen_for_wake_word(wake_word=\"hey robot\"):\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening for wake word...\")\n",
    "        audio = r.listen(source)\n",
    "\n",
    "    try:\n",
    "        text = r.recognize_google(audio, language=\"en-US\")\n",
    "        if wake_word.lower() in text.lower():\n",
    "            print(\"Wake word detected!\")\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Could not understand audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Error; {e}\")\n",
    "\n",
    "    return False\n",
    "\n",
    "# Function to execute after wake word is detected\n",
    "def execute_script():\n",
    "    print(\"Executing script...\")\n",
    "    # Add your script code here\n",
    "\n",
    "# Main loop\n",
    "while True:\n",
    "    if listen_for_wake_word():\n",
    "        execute_script()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Speech-to-Text**\n",
    "\n",
    "Note : Rajouter stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You said: go forward then go left\n"
     ]
    }
   ],
   "source": [
    "# Create a recognizer object\n",
    "try:\n",
    "    # Use the recognizer to convert speech to text\n",
    "    text = r.recognize_google(audio)\n",
    "    print(\"You said:\", text)\n",
    "\n",
    "    # Save the transcribed text to a file\n",
    "    with open(\"transcript.txt\", \"w\") as file:\n",
    "        file.write(text + \"\\n\")\n",
    "\n",
    "except sr.UnknownValueError as e:\n",
    "    print(\"Sorry, I could not understand your speech.\")\n",
    "\n",
    "except sr.RequestError as e:\n",
    "    print(\"Sorry, an error occurred. Please check your internet connection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Context recognition**\n",
    "\n",
    "Note : Rajouter trigger by response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command\n"
     ]
    }
   ],
   "source": [
    "with open(\"transcript.txt\", \"r\") as file:\n",
    "    context_variable = file.read()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "You must only answer by \"command\" or \"speech\".\n",
    "\n",
    "For your knowledge, here are some possible commands:\n",
    "\"left\": \"go to the left\",\n",
    "\"right\": \"go to the right\",\n",
    "\"forward\": \"go forward\",\n",
    "\"ahead\": \"go forward\",\n",
    "\"backward\": \"go backward\",\n",
    "\"back\": \"go backward\",\n",
    "\"u-turn\": \"make a U-turn\",\n",
    "\"stop\": \"stop\"\n",
    "\"return to your base\": \"return to base\"\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\",\"question\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-1106-preview\",temperature=0)\n",
    "# The prompt here should take as an input variable the\n",
    "# `document_variable_name`\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "query = \"Is this transcripted text about a movement command or a speech ?\"\n",
    "res1 = llm_chain.run(context=context_variable, question=query)\n",
    "print(res1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Segmentation between Text-to-command and Text summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res1 in [res1]:\n",
    "    if res1 == \"command\":\n",
    "        # Execute the command script\n",
    "        # Add your code here for the command script\n",
    "\n",
    "    elif res1 == \"speech\":\n",
    "        with open(\"transcript.txt\", \"r\") as file:\n",
    "            context_variable = file.read()\n",
    "\n",
    "            template = \"\"\"Synthetise the following conversation:\n",
    "\n",
    "            {context}\n",
    "            You must capable of:\n",
    "            - Understand the context of the conversation. \n",
    "                Example 1: A patient requires medical attention.\n",
    "                Example 2: A doctor is talking to a patient.\n",
    "                Example 3: A doctor is giving you information.\n",
    "            - Differenciate the different persons in the conversation.\n",
    "            \"\"\"\n",
    "\n",
    "            prompt = PromptTemplate(\n",
    "             input_variables=[\"context\"],\n",
    "             template=template\n",
    "            )\n",
    "\n",
    "            llm = ChatOpenAI(model=\"gpt-4-1106-preview\",temperature=0)\n",
    "                # The prompt here should take as an input variable the\n",
    "                # `document_variable_name`\n",
    "\n",
    "            llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "            \n",
    "            res_speech = llm_chain.run(context=context_variable)\n",
    "                    \n",
    "    pass  # Add an indented block of code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rajouter command de déplacement 360 pour acknowledge fin de mission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
